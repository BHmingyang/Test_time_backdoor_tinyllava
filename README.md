# 针对TinyLLava测试阶段的后门攻击算法

本项目实现了针对TinyLLaVA测试阶段的后门攻击算法。

## 数据准备
用户可根据任务需求灵活定制专属数据集。在数据源层面，支持从公开视觉问答数据集（如VQA、SVIT）或自定义图像库中选取视觉素材，同时允许通过手动设计或调用预训练语言模型（如GPT）自动生成关联问题。用户指定需要攻击的小尺寸多模态模型，调用model_inference.py，目标模型即可基于图像-问题对生成语义连贯的响应结果作为伪标签。在数据组织阶段，用户只需将图像、文本和模型生成的答案构建成三元组：图像路径字段支持绝对路径或相对路径配置，问题描述字段兼容多轮对话扩展格式，生成答案字段自动继承模型输出结果。最终数据集按照层级结构进行序列化存储并存放在data目录下。

## 训练流程
本代码的训练流程采用全自动化执行框架，用户仅需通过声明式配置文件或交互式命令行界面指定核心参数即可启动攻击任务。在模型接入层面，系统支持多种小尺寸的主流视觉-语言预训练模型（如TinyLLava-Qwen2-0.5B-SigLip、TinyLLava-Phi-2-SigLIP-3.1B）的即插即用式适配，通过标准化API接口自动加载目标模型权重并冻结主干网络参数。攻击参数配置模块采用多层级可调架构：用户可自定义攻击样本数量、扰动生成强度、扰动范围、训练迭代周期、学习率调度策略、触发器、目标输出及损失函数的权重等参数。当用户确认配置并运行Test_time_backdoor_train.py后，系统将自动进入对抗性扰动优化阶段：首先基于用户所指定的攻击策略定位关键扰动区域，随后通过基于投影梯度下降和频域增强的扰动优化策略进行多步扰动迭代。整个训练过程采用分布式GPU加速计算框架，支持混合精度训练和梯度累积技术。训练结束后将自动生成包含扰动参数矩阵、攻击日志、多模态大模型在训练阶段的输出、可视化扰动的完整报告，并支持导出.pth格式的扰动参数以供后续的评估和部署。
在训练脚本train.sh指定训练参数后，用户可通过以下命令启动训练任务：
```
bash train.sh
```

## 评估框架
在训练阶段完成后，用户仅需执行两步操作并运行Test_time_backdoor_eval.py即可获取多维评估结果：首先通过API接口加载训练阶段生成的扰动参数矩阵（.pth格式文件），随后指定对应的攻击策略类型（像素/角点/边界攻击）。代码将自动触发两重验证机制：第一层执行攻击策略一致性验证，检测参数矩阵与指定攻击模式的空间约束条件（如边界攻击的扰动范围b）是否匹配；第二层启动多模态评估器，同步加载原始模型权重与扰动参数构建对抗样本生成管道。评估过程采用多维度的评估体系，从攻击效果和正常性能两个维度对结果进行全面分析。攻击效果方面从精准匹配率和内容包含率两个方面进行衡量，正常性能方面从BLEU4和ROUGE-L两个方面进行衡量。评估结果将以表格形式展示，同时支持导出详细的评估日志和可视化结果，为用户提供全面的评估报告。
在评估脚本eval.sh指定训练中使用的攻击策略后，用户可通过以下命令启动评估任务：
```
bash eval.sh
```

## 致谢
本项目基于以下开源项目进行开发：
https://github.com/sail-sg/AnyDoor/tree/main
https://github.com/TinyLLaVA/TinyLLaVA_Factory
Great Work！Thanks for sharing!